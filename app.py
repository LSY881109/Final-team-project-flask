from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import os
import time
import json  # JSON ì‘ë‹µì„ ë” ê¹”ë”í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ import
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import gc

# from werkzeug.utils import secure_filename # ì‹¤ì œ íŒŒì¼ ì´ë¦„ ë³´ì•ˆ ì²˜ë¦¬ ì‹œ í•„ìš”

app = Flask(__name__)
# CORS ì„¤ì •: Spring Boot ì„œë²„ì™€ React ê°œë°œ ì„œë²„ì—ì„œì˜ ìš”ì²­ í—ˆìš©
# ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•´ CORS í—ˆìš© (ê°œë°œìš©)
CORS(app, origins=[
    "http://localhost:8080",
    "http://127.0.0.1:8080",
    "http://localhost:5173"
], methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"], allow_headers=["Content-Type", "Authorization"])
# Flask ì„œë²„ë¥¼ ì‹¤í–‰í•  í¬íŠ¸ (Spring Bootì˜ application.propertiesì™€ ì¼ì¹˜í•´ì•¼ í•¨)
# macOSì˜ AirPlay Receiverê°€ 5000 í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ 5001ë¡œ ë³€ê²½
FLASK_PORT = 5001

# í´ë˜ìŠ¤ ì´ë¦„
class_names = ['ê°ë°”ìŠ¤', 'ìˆ¯ë¶ˆì¹˜í‚¨', 'ì–‘ë…ì¹˜í‚¨', 'íŒŒìŠ¤íƒ€', 'í›„ë¼ì´ë“œì¹˜í‚¨']

# ë””ë°”ì´ìŠ¤ ì„¤ì •
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("ğŸ Apple Silicon GPU (MPS) ì‚¬ìš©!")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("ğŸ”¥ CUDA GPU ì‚¬ìš©!")
else:
    device = torch.device("cpu")
    print("ğŸ’» CPU ì‚¬ìš©")

# EfficientNet ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_efficientnet(model_path="efficientnet_finetuned_best.pth", num_classes=5):
    model = models.efficientnet_b0(pretrained=False)
    num_ftrs = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(num_ftrs, num_classes)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    return model

# BiRefNet ë°°ê²½ ì œê±° ëª¨ë¸ ë¡œë“œ (ê¸°ë³¸ê°’: í™œì„±í™”)
ENABLE_BACKGROUND_REMOVAL = True  # Falseë¡œ ë³€ê²½í•˜ë©´ ë°°ê²½ ì œê±° ë¹„í™œì„±í™”

birefnet_model = None
if ENABLE_BACKGROUND_REMOVAL:
    try:
        print("ğŸ¤– BiRefNet ë°°ê²½ ì œê±° ëª¨ë¸ ë¡œë”© ì¤‘...")
        from transformers import AutoModelForImageSegmentation
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        if torch.backends.mps.is_available():
            torch.mps.empty_cache()
        elif torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        birefnet_model = AutoModelForImageSegmentation.from_pretrained(
            'ZhengPeng7/BiRefNet',
            trust_remote_code=True,
            torch_dtype=torch.float16 if device.type != 'cpu' else torch.float32,
            low_cpu_mem_usage=True
        )
        birefnet_model.to(device)
        birefnet_model.eval()
        
        if device.type == 'mps':
            torch.mps.empty_cache()
        elif device.type == 'cuda':
            torch.cuda.empty_cache()
        
        print("âœ… BiRefNet ë°°ê²½ ì œê±° ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    except ImportError as e:
        print(f"âš ï¸  transformers ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
        print("âš ï¸  ë°°ê²½ ì œê±° ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        print("ğŸ’¡ pip install transformers ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        birefnet_model = None
    except Exception as e:
        print(f"âš ï¸  BiRefNet ë¡œë”© ì‹¤íŒ¨: {e}")
        print("âš ï¸  ë°°ê²½ ì œê±° ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        birefnet_model = None
else:
    print("â„¹ï¸  ë°°ê²½ ì œê±° ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨ (ë¹ ë¥¸ ì‹œì‘)")

# ëª¨ë¸ ë¡œë“œ
model = load_efficientnet()

# ë°°ê²½ ì œê±° í•¨ìˆ˜ (BiRefNet ì‚¬ìš©)
def remove_background(image, birefnet_model, device):
    """
    BiRefNetì„ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ ì œê±°
    """
    if birefnet_model is None:
        return image
    
    try:
        # BiRefNet ì…ë ¥ ì „ì²˜ë¦¬
        input_size = (1024, 1024)
        transform = transforms.Compose([
            transforms.Resize(input_size),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        input_tensor = transform(image).unsqueeze(0).to(device)
        # float16ìœ¼ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if device.type != 'cpu':
            input_tensor = input_tensor.half()
        
        # ë°°ê²½ ì œê±°
        with torch.no_grad():
            preds = birefnet_model(input_tensor)[-1].sigmoid().cpu()
        
        pred = preds[0].squeeze()
        pred_pil = transforms.ToPILImage()(pred)
        mask = pred_pil.resize(image.size)
        
        # RGBAë¡œ ë³€í™˜ (ì•ŒíŒŒ ì±„ë„ì— ë§ˆìŠ¤í¬ ì ìš©)
        image_rgba = image.convert("RGBA")
        image_rgba.putalpha(mask)
        
        # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ í•©ì„±
        white_bg = Image.new("RGB", image.size, (255, 255, 255))
        white_bg.paste(image_rgba, (0, 0), image_rgba)
        
        return white_bg
    except Exception as e:
        print(f"ë°°ê²½ ì œê±° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return image

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ë°°ê²½ ì œê±° + ë¦¬ì‚¬ì´ì¦ˆ + íŒ¨ë”©)
def preprocess_image(image, remove_bg=True):
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ë°°ê²½ ì œê±° â†’ ë¦¬ì‚¬ì´ì¦ˆ â†’ íŒ¨ë”© â†’ ì •ê·œí™”
    remove_bg: ë°°ê²½ ì œê±° ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True - BiRefNet ì‚¬ìš©)
    """
    original_size = image.size
    
    # 1. ë°°ê²½ ì œê±° (ê¸°ë³¸ê°’: í™œì„±í™” - BiRefNet ì‚¬ìš©)
    if remove_bg and birefnet_model is not None:
        image = remove_background(image, birefnet_model, device)
    
    # 2. 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ + íŒ¨ë”© (ë¹„ìœ¨ ìœ ì§€)
    target_size = (224, 224)
    image.thumbnail(target_size, Image.Resampling.LANCZOS)
    
    # íŒ¨ë”© ì¶”ê°€ (í°ìƒ‰ ë°°ê²½)
    new_image = Image.new("RGB", target_size, (255, 255, 255))
    paste_position = ((target_size[0] - image.size[0]) // 2,
                      (target_size[1] - image.size[1]) // 2)
    new_image.paste(image, paste_position)
    
    # 3. ëª¨ë¸ ì…ë ¥ìš© ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    return transform(new_image).unsqueeze(0).to(device)


# Spring Bootì˜ application.propertiesì— ì„¤ì •ëœ flask.api.url=http://localhost:5000 ì— ëŒ€ì‘

# ----------------------------------------------------
# ğŸš© í…ŒìŠ¤íŠ¸ìš© ì›¹í˜ì´ì§€ ë Œë”ë§
# ----------------------------------------------------
@app.route('/')
def index():
    return render_template('index.html')

# ----------------------------------------------------
# ğŸš© í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ë¶„ë¥˜ API
# ----------------------------------------------------
@app.route('/classify', methods=['POST'])
def classify_image():
    """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ë¶„ë¥˜ API"""
    if 'image' not in request.files:
        return jsonify({"error": "No image file"}), 400

    image_file = request.files['image']
    if image_file.filename == "":
        return jsonify({"error": "No selected file"}), 400

    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ëª¨ë¸ ì˜ˆì¸¡ (ë°°ê²½ ì œê±° ê¸°ë³¸ê°’: í™œì„±í™”)
        image = Image.open(image_file).convert('RGB')
        # ë°°ê²½ ì œê±° ì˜µì…˜ (ê¸°ë³¸ê°’: true, falseë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥)
        remove_bg = request.args.get('remove_bg', 'true').lower() == 'true'
        image_tensor = preprocess_image(image, remove_bg=remove_bg)

        with torch.no_grad():
            output = model(image_tensor)
            probabilities = torch.nn.functional.softmax(output[0], dim=0)
            predicted_idx = torch.argmax(probabilities).item()
            confidence = probabilities[predicted_idx].item()

        # ìƒìœ„ 3ê°œ ê²°ê³¼
        top3_probs, top3_indices = torch.topk(probabilities, min(3, len(class_names)))
        
        results = []
        for i in range(len(top3_indices)):
            results.append({
                "class": class_names[top3_indices[i].item()],
                "confidence": round(top3_probs[i].item() * 100, 2)
            })

        return jsonify({
            "predicted_class": class_names[predicted_idx],
            "confidence": round(confidence * 100, 2),
            "top3": results
        }), 200
        
    except Exception as e:
        print(f"Error during image classification: {str(e)}")
        return jsonify({"error": f"Error during image classification: {str(e)}"}), 500

# ----------------------------------------------------
# ğŸš© ìŒì‹ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸: Spring Bootì˜ AIAnalysisServiceê°€ í˜¸ì¶œí•  ê²½ë¡œ
# ----------------------------------------------------
@app.route('/analyze', methods=['POST'])
def analyze_image():
    # 1. Spring Bootë¡œë¶€í„° ìš”ì²­ ìˆ˜ì‹  í™•ì¸
    if 'image' not in request.files:
        print("Error: 'image' file part not found in the request.")
        return jsonify({"message": "No image file provided"}), 400

    image_file = request.files['image']
    
    if image_file.filename == "":
        return jsonify({"message": "No selected file"}), 400

    # 2. íŒŒì¼ ì •ë³´ í™•ì¸
    filename = image_file.filename
    print(f"Received file: {filename}")

    try:
        # 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ëª¨ë¸ ì˜ˆì¸¡ (ë°°ê²½ ì œê±°ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™” - ë¹ ë¥¸ ì²˜ë¦¬)
        image = Image.open(image_file).convert('RGB')
        # ë°°ê²½ ì œê±°ëŠ” ëŠë¦¬ë¯€ë¡œ ê¸°ë³¸ê°’ False, í•„ìš”ì‹œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ í™œì„±í™” ê°€ëŠ¥
        remove_bg = request.args.get('remove_bg', 'false').lower() == 'true'
        image_tensor = preprocess_image(image, remove_bg=remove_bg)

        with torch.no_grad():
            output = model(image_tensor)
            probabilities = torch.nn.functional.softmax(output[0], dim=0)
            predicted_idx = torch.argmax(probabilities).item()
            confidence = probabilities[predicted_idx].item()

        # 4. ì˜ˆì¸¡ ê²°ê³¼ (Spring Bootì˜ AiResponse DTOì— ë§ì¶° ë‘ ê°€ì§€ë§Œ ë°˜í™˜)
        food_name = class_names[predicted_idx]
        confidence_score = round(confidence * 100, 2)  # 0.0~1.0 â†’ 0.0~100.0ìœ¼ë¡œ ë³€í™˜

        # 5. Spring Bootì˜ AiResponse DTO í˜•ì‹ì— ë§ì¶˜ JSON ì‘ë‹µ êµ¬ì„±
        # Spring Bootì—ì„œ ë‚˜ë¨¸ì§€ ì •ë³´(ì¹¼ë¡œë¦¬, ì˜ì–‘ì •ë³´, ë ˆì‹œí”¼ ë“±)ëŠ” DBì—ì„œ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬
        response_data = {
            "class": food_name,  # AiResponseì˜ predictedClass í•„ë“œì™€ ë§¤í•‘
            "confidence": confidence_score  # AiResponseì˜ confidence í•„ë“œì™€ ë§¤í•‘
        }

        # 6. JSON ì‘ë‹µ ë°˜í™˜
        return jsonify(response_data), 200
        
    except Exception as e:
        print(f"Error during image analysis: {str(e)}")
        return jsonify({
            "class": "ì¸ì‹í•  ìˆ˜ ì—†ëŠ” ìŒì‹",
            "confidence": 0.0
        }), 500


# ----------------------------------------------------
# ğŸš© ì„œë²„ ì‹¤í–‰
# ----------------------------------------------------
if __name__ == '__main__':
    print(f"Flask server is running on http://127.0.0.1:{FLASK_PORT}")
    # debug=TrueëŠ” ê°œë°œìš©ì…ë‹ˆë‹¤. (ë°°í¬ ì‹œì—ëŠ” ë„ì„¸ìš”)
    app.run(host='0.0.0.0', port=FLASK_PORT, debug=True)